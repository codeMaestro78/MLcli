# AutoML Design Document

## ğŸ¯ Scope Definition

### AutoML Mode: **Model-Centric AutoML**

Based on the existing mlcli architecture, I recommend a **Model-Centric AutoML** approach that:

1. Leverages existing trainers, tuners, and preprocessors
2. Adds intelligent model selection and comparison
3. Maintains backward compatibility
4. Follows existing design patterns

### In Scope

| Feature                         | Priority | Rationale                               |
| ------------------------------- | -------- | --------------------------------------- |
| Automatic Model Selection       | P0       | Core AutoML value proposition           |
| Automatic Hyperparameter Tuning | P0       | Leverage existing tuner infrastructure  |
| Automatic Preprocessing         | P1       | Leverage existing preprocessor pipeline |
| Multi-Model Comparison          | P1       | Essential for AutoML reporting          |
| Time Budget Management          | P1       | Production requirement                  |
| Ensemble Creation               | P2       | Advanced AutoML feature                 |
| Feature Engineering             | P2       | Adds ML value                           |
| Early Stopping                  | P2       | Efficiency optimization                 |

### Out of Scope (v1)

- Neural Architecture Search (NAS)
- AutoML for Deep Learning model architecture
- Distributed/parallel AutoML
- AutoML for computer vision/NLP-specific tasks
- Custom loss function optimization

## ğŸ—ï¸ Architecture Strategy

### Option Analysis

| Strategy                           | Pros                      | Cons                           | Recommendation  |
| ---------------------------------- | ------------------------- | ------------------------------ | --------------- |
| **A) New AutoML Module**           | Clean separation, focused | Code duplication               | âœ… **Selected** |
| B) Extend Tuners                   | Reuse existing code       | Overloads tuner responsibility | âŒ              |
| C) External Library (auto-sklearn) | Battle-tested             | Dependency bloat, less control | âŒ              |

### Chosen Architecture: New `mlcli/automl/` Module

```
mlcli/
â”œâ”€â”€ automl/                      # NEW MODULE
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ base_automl.py           # BaseAutoML abstract class
â”‚   â”œâ”€â”€ automl_classifier.py     # AutoML for classification
â”‚   â”œâ”€â”€ automl_regressor.py      # AutoML for regression (future)
â”‚   â”œâ”€â”€ model_selector.py        # Model selection logic
â”‚   â”œâ”€â”€ search_space.py          # Default param spaces per model
â”‚   â”œâ”€â”€ data_analyzer.py         # Data type/quality analysis
â”‚   â”œâ”€â”€ preprocessing_selector.py # Auto preprocessing selection
â”‚   â”œâ”€â”€ ensemble_builder.py      # Voting/Stacking ensemble (P2)
â”‚   â””â”€â”€ reporter.py              # AutoML run reports
```

## ğŸ”„ Proposed AutoML Workflow

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    mlcli automl --config                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â”‚
                              â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  1. DATA ANALYSIS (data_analyzer.py)                        â”‚
â”‚     â€¢ Infer data types (numeric, categorical, text)         â”‚
â”‚     â€¢ Detect missing values, class imbalance                â”‚
â”‚     â€¢ Determine task type (classification/regression)       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â”‚
                              â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  2. PREPROCESSING SELECTION (preprocessing_selector.py)     â”‚
â”‚     â€¢ Select appropriate scalers                            â”‚
â”‚     â€¢ Select encoders for categorical features              â”‚
â”‚     â€¢ Select feature selection method                       â”‚
â”‚     â€¢ Build PreprocessingPipeline                           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â”‚
                              â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  3. MODEL SELECTION (model_selector.py)                     â”‚
â”‚     â€¢ Filter compatible models from Registry                â”‚
â”‚     â€¢ Optionally filter by user preferences (fast/accurate) â”‚
â”‚     â€¢ Generate candidate list                               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â”‚
                              â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  4. SEARCH SPACE GENERATION (search_space.py)               â”‚
â”‚     â€¢ Get default param_space for each model                â”‚
â”‚     â€¢ Adjust based on data size (smaller space for big data)â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â”‚
                              â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  5. MODEL TRAINING & TUNING (Reuse existing tuners)         â”‚
â”‚     â€¢ For each candidate model:                             â”‚
â”‚       - Use OptunaTuner (Bayesian) for efficiency           â”‚
â”‚       - Track with ExperimentTracker                        â”‚
â”‚       - Respect time budget                                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â”‚
                              â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  6. COMPARISON & RANKING (reporter.py)                      â”‚
â”‚     â€¢ Rank models by scoring metric                         â”‚
â”‚     â€¢ Generate comparison report                            â”‚
â”‚     â€¢ Return best model or ensemble                         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â”‚
                              â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  7. OUTPUT                                                   â”‚
â”‚     â€¢ Save best model (via Trainer.save())                  â”‚
â”‚     â€¢ Save AutoML report (JSON/HTML)                        â”‚
â”‚     â€¢ Log to ExperimentTracker                              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ğŸ“‹ Configuration Schema

### New `automl_config.json` Format

```json
{
  "dataset": {
    "path": "data/train.csv",
    "target_column": "label"
  },
  "automl": {
    "task": "classification",
    "metric": "accuracy",
    "time_budget_minutes": 30,
    "models": ["random_forest", "xgboost", "lightgbm", "logistic_regression"],
    "models": "auto",
    "tuning_method": "bayesian",
    "n_trials_per_model": 50,
    "cv_folds": 5,
    "preprocessing": "auto",
    "ensemble": false,
    "early_stopping_rounds": 10 
  },
  "training": {
    "test_size": 0.2,
    "random_state": 42
  },
  "output": {
    "model_dir": "artifacts/automl",
    "report_path": "reports/automl_report.html",
    "save_all_models": false
  }
}
```

## ğŸ”Œ Integration Points

### 1. CLI Integration

```python
# New command in cli.py
@app.command("automl")
def automl_run(
    config: Path,
    time_budget: int = 30,
    metric: str = "accuracy",
    models: List[str] = None,
    verbose: bool = True,
):
    """Run AutoML pipeline."""
```

### 2. Registry Integration

```python
# Use existing registry to get compatible models
registry = get_registry()
classification_models = registry.get_models_by_type("classification")
```

### 3. Tuner Integration

```python
# Reuse OptunaTuner for each model
tuner = TunerFactory.create("bayesian", param_space, n_trials=50)
results = tuner.tune(trainer_class, X, y)
```

### 4. Tracker Integration

```python
# Log AutoML runs to experiment tracker
tracker.start_run(model_type="automl", config=automl_config)
tracker.log_params({"candidate_models": models, "time_budget": time_budget})
tracker.log_metrics({"best_model": best_model, "best_score": best_score})
```

## ğŸ” Assumptions

1. **Classification First**: Initial implementation focuses on classification tasks
2. **Scikit-learn Models**: Only sklearn-compatible models in v1 AutoML
3. **Tabular Data**: Only CSV/tabular data supported
4. **Single Machine**: No distributed AutoML
5. **Existing Models Only**: Use registered trainers, no new model implementations
6. **Bayesian Default**: Use Optuna (TPE) as default tuning method for efficiency

## ğŸ“Š Success Metrics

1. AutoML should find model within 5% of manual tuning performance
2. Time budget should be respected (Â±10%)
3. All existing CLI commands continue to work unchanged
4. Memory usage stays within 2x of single model training

---

_Document generated for AutoML Integration Planning_
_Phase 1 - Design Strategy_
